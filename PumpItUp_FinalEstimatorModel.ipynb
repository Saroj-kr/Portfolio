{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA,TruncatedSVD\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer,f1_score,log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_Train.csv',index_col=[0],infer_datetime_format=True,parse_dates=['date_recorded'],keep_date_col=True)\n",
    "y = pd.read_csv('Y_Train.csv',index_col=[0])\n",
    "y = y['status_group']\n",
    "X_pred = pd.read_csv('X_test.csv',index_col=[0],infer_datetime_format=True,parse_dates=['date_recorded'],keep_date_col=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_columns = X.select_dtypes(include='number').columns.values\n",
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columnwodate = ['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private',\n",
    "       'region_code', 'district_code', 'population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfEstimatorModel = Pipeline([\n",
    "    ('cs',ColumnSelector(num_columns)),\n",
    "    ('si',SimpleImputer(missing_values=0,strategy='median')),\n",
    "    ('ss',StandardScaler()),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=80,max_depth=90))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfEstimatorModel.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputer Strategy scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputer Stratgey : Most Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfEstimatorModel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputer Strategy : Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfEstimatorModel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputer Strategy : median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfEstimatorModel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going forward with Imputer strategy : Median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving last model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumFeature_Pipeline = Pipeline([\n",
    "    ('si',SimpleImputer(missing_values=0,strategy='median'))\n",
    "])\n",
    "\n",
    "rfEstimatorModel2 = Pipeline([\n",
    "    ('ct', ColumnTransformer([\n",
    "        ('num_ct', NumFeature_Pipeline, num_columns)\n",
    "    ])),\n",
    "    ('ss',StandardScaler()),\n",
    "    ('rfc', RandomForestClassifier(n_estimators=80,max_depth=90))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfEstimatorModel2.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfEstimatorModel2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing num_column to remove construction_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_column = ['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private',\n",
    "       'region_code', 'district_code', 'population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfEstimatorModel2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score decreased, Continuing with having construction_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking other Classification models with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    'Random Forest Classifier' : RandomForestClassifier(),\n",
    "    'Support Vector Classifier' : SVC(),\n",
    "    'Ridge Classifier' : RidgeClassifier(),\n",
    "    'K Nearest Neighbors' : KNeighborsClassifier(n_neighbors=3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NumFeature_Pipeline = Pipeline([\n",
    "    ('si',SimpleImputer(missing_values=0,strategy='median'))\n",
    "])\n",
    "\n",
    "for key,estimator in estimators.items():\n",
    "    print('Estimating using Classifier : ', key)\n",
    "    EstimatorModel3 = Pipeline([\n",
    "        ('ct', ColumnTransformer([('num_ct', NumFeature_Pipeline, num_columns)])),\n",
    "        ('ss',StandardScaler()),\n",
    "        ('estimator', estimator)\n",
    "    ])\n",
    "    \n",
    "    print(\"Fitting Model\")\n",
    "    EstimatorModel3.fit(X_train,y_train);\n",
    "    \n",
    "    print(\"Calculating Score\")\n",
    "    score = EstimatorModel3.score(X_test,y_test)\n",
    "    \n",
    "    print(\"Score = \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pump It Up Final Prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X_Train.csv',index_col=[0],infer_datetime_format=True,parse_dates=['date_recorded'],keep_date_col=True)\n",
    "y = pd.read_csv('Y_Train.csv',index_col=[0])\n",
    "y = y['status_group']\n",
    "X_pred = pd.read_csv('X_test.csv',index_col=[0],infer_datetime_format=True,parse_dates=['date_recorded'],keep_date_col=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split data into Training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extracting categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "cat_columns = X_test.select_dtypes(exclude=['number','datetime64[ns]']).columns.values\n",
    "cat_columns = cat_columns.tolist()\n",
    "cat_columns.append('construction_year')\n",
    "num_columnwoLatLngNyear = ['amount_tsh', 'gps_height', 'num_private',\n",
    "       'region_code', 'district_code', 'population']\n",
    "LatLng_Feature = ['longitude', 'latitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Transformation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumFeature_Pipeline = Pipeline([\n",
    "    ('si', SimpleImputer(missing_values=0,strategy='median')),\n",
    "    ('ss', MinMaxScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatFeature_Pipeline = Pipeline([\n",
    "    ('si1', SimpleImputer(missing_values=np.NaN,strategy='most_frequent')),\n",
    "    ('si2', SimpleImputer(missing_values=0,strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore',sparse=True)),\n",
    "    ('pca', TruncatedSVD(80))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submission Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePred(estimatorModel):\n",
    "    y_pred = estimatorModel.predict(X_pred)\n",
    "    y_predictions = pd.DataFrame(list(zip(X_pred.index,y_pred)),columns=['id','status_group'])\n",
    "    y_predictions.to_csv(datetime.datetime.now().strftime(\"%d%m%Y%H%M%S\")+'_Submission.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi Estimator Predictor Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = mkdtemp()\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_metric = make_scorer(f1_score, average = 'weighted')\n",
    "log_loss_score_metric = make_scorer(log_loss, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoringMetrics = [f1_score_metric,\n",
    "                  log_loss_score_metric]\n",
    "\n",
    "estimators = {\n",
    "    'RFC' : RandomForestClassifier(),\n",
    "    #'NB' : GaussianNB()\n",
    "    #'KNN' : KNeighborsClassifier()\n",
    "    #'Gradient Booster' : GradientBoostingClassifier(learning_rate=0.2)\n",
    "}\n",
    "\n",
    "params = {'RFC' : {'criterion':['entropy'], 'n_estimators':[70,80,90],\n",
    "                   'min_samples_leaf':[3,5,7], 'min_samples_split':[5,7,9],\n",
    "                   'max_depth':[70,80,90], 'n_jobs':[-1], 'random_state':[42]},\n",
    "         'NB' : {}}\n",
    "\n",
    "#params = {'RFC' : {'criterion':['gini','entropy'], 'n_estimators':[30, 50, 80],\n",
    "#                   'min_samples_leaf':[1,2,3], 'min_samples_split':[3,4,5,6,7],\n",
    "#                   'max_depth':[80, 90], 'n_jobs':[-1], 'random_state':[42]},\n",
    "#          'KNN' : {'n_neighbors':[3,5,6,7], 'leaf_size':[1,2,3,5], 'n_jobs':[-1],\n",
    "#                   'weights':['uniform', 'distance'], 'algorithm':['auto', 'ball_tree', 'kd_tree','brute']}}\n",
    "\n",
    "for key,estimator in estimators.items():\n",
    "    print('Estimating using Classifier : ', key)\n",
    "    \n",
    "    \n",
    "    EstimatorModel4 = Pipeline([\n",
    "        ('ct', ColumnTransformer([\n",
    "            ('num_ct', NumFeature_Pipeline, num_columnwoLatLngNyear),\n",
    "            ('cat_ct', CatFeature_Pipeline, cat_columns),\n",
    "            ('latlng_ct', 'passthrough', LatLng_Feature),\n",
    "        ])),\n",
    "        ('gs', GridSearchCV(estimator,param_grid=params[key],cv=3, n_jobs=-1, verbose=1, scoring=f1_score_metric,\n",
    "                            refit='f1'))\n",
    "    ], memory=cachedir)\n",
    "    \n",
    "    #print(\"Fitting Model over Test Data\")\n",
    "    #EstimatorModel4.fit(X_train,y_train);\n",
    "    #score = EstimatorModel4.score(X_test,y_test)\n",
    "    #print(score)\n",
    "    #results.append({'estimator':key, 'score':score, 'Best_Params':EstimatorModel4.named_steps['gs'].best_params_})\n",
    "    \n",
    "    #print(\"Calculating Score : \",end=None)\n",
    "    \n",
    "    #print(\"Test Score = \", score)\n",
    "    \n",
    "    print(\"Fitting Model over Full Data\")\n",
    "    EstimatorModel4.fit(X,y);\n",
    "    #print(EstimatorModel4.best_estimator_)\n",
    "    #print(EstimatorModel4.best_params_)\n",
    "    \n",
    "    #score = EstimatorModel4.score(X,y)\n",
    "    results.append({'estimator':key, 'results':EstimatorModel4.named_steps['gs'].cv_results_,\n",
    "                    'Best_Params':EstimatorModel4.named_steps['gs'].best_params_})\n",
    "    #print(\"Calculating Score : \",end=None)\n",
    "    \n",
    "    #print(score)\n",
    "\n",
    "    print(results)\n",
    "#pd.DataFrame(results).to_csv(datetime.datetime.now().strftime(\"%d%m%Y%H%M%S\")+'_Submission.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single Estimator Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EstimatorModel5 = Pipeline([\n",
    "        ('ct', ColumnTransformer([\n",
    "            ('num_ct', NumFeature_Pipeline, num_columnwoLatLngNyear),\n",
    "            ('cat_ct', CatFeature_Pipeline, cat_columns),\n",
    "            ('latlng_ct', 'passthrough', LatLng_Feature),\n",
    "        ])),\n",
    "        ('rfc', RandomForestClassifier(criterion='entropy', max_depth=70, min_samples_leaf=3, min_samples_split=7,\n",
    "                                       n_estimators=90, n_jobs=-1, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EstimatorModel7 = Pipeline([\n",
    "        ('ct', ColumnTransformer([\n",
    "            ('num_ct', NumFeature_Pipeline, num_columnwoLatLngNyear),\n",
    "            ('cat_ct', CatFeature_Pipeline, cat_columns),\n",
    "            ('latlng_ct', 'passthrough', LatLng_Feature),\n",
    "        ])),\n",
    "        ('rfc', RandomForestClassifier(criterion='entropy', max_depth=80, min_samples_leaf=7, min_samples_split=7, n_estimators=80, n_jobs=1, random_state=42))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ct',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num_ct',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('si',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=0,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('ss',\n",
       "                                                                   MinMaxScaler(copy=True,\n",
       "                                                                                feature_range=(0,\n",
       "                                                                                               1)))],\n",
       "                                                           verbos...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='entropy',\n",
       "                                        max_depth=70, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=3, min_samples_split=7,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=90, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=42,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EstimatorModel5.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writePred(EstimatorModel5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EstimatorModel5.fit(X_train,y_train)\n",
    "writePred(EstimatorModel5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EstimatorModel6 = Pipeline([\n",
    "        ('ct', ColumnTransformer([\n",
    "            ('num_ct', NumFeature_Pipeline, num_columnwoLatLngNyear),\n",
    "            ('cat_ct', CatFeature_Pipeline, cat_columns),\n",
    "            ('latlng_ct', 'passthrough', LatLng_Feature),\n",
    "        ])),\n",
    "        ('knn', KNeighborsClassifier(algorithm='brute', leaf_size=1, n_jobs=-1, n_neighbors=7, weights='distance'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EstimatorModel6.fit(X,y)\n",
    "writePred(EstimatorModel6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EstimatorModel6.fit(X_train,y_train)\n",
    "writePred(EstimatorModel6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
